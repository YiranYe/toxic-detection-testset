{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    there are some incredibly Stuuupidd people on ...\n",
      "0    there are some incredibly Stuuupidd people on ...\n",
      "0    there are some incredibly Stuuupidd people on ...\n",
      "0                           thats just plain Stuuupidd\n",
      "0                           thats just plain Stuuupidd\n",
      "0                           thats just plain Stuuupidd\n",
      "0    typical empty Stuuupidd reply based on hate ov...\n",
      "0    typical empty Stuuupidd reply based on hate ov...\n",
      "0    typical empty Stuuupidd reply based on hate ov...\n",
      "0                i always knew you were a dirtyyyy cop\n",
      "0                i always knew you were a dirtyyyy cop\n",
      "0                i always knew you were a dirtyyyy cop\n",
      "0                 DUMBBBB response off topic as always\n",
      "0                 DUMBBBB response off topic as always\n",
      "0                 DUMBBBB response off topic as always\n",
      "0                i DAAAAMN no one they damn themselves\n",
      "0                i daaammn no one they damn themselves\n",
      "0                i DAMNNNN no one they damn themselves\n",
      "0    wow that is a whole of Stuuupidd and ugly that...\n",
      "0    wow that is a whole of Stuuupidd and ugly that...\n",
      "0    wow that is a whole of Stuuupidd and ugly that...\n",
      "0    and you lost the cold war wow my response is a...\n",
      "0    and you lost the cold war wow my response is a...\n",
      "0    and you lost the cold war wow my response is a...\n",
      "0                               you cant fix Stuuupidd\n",
      "0                               you cant fix Stuuupidd\n",
      "0                               you cant fix Stuuupidd\n",
      "0                            Daaaamn you beat me to it\n",
      "0                            Damnnnn you beat me to it\n",
      "0                            dammmmn you beat me to it\n",
      "0    good job tracker without snow the guy might ne...\n",
      "0    good job tracker without snow the guy might ne...\n",
      "0    good job tracker without snow the guy might ne...\n",
      "0                     ah to be fat drunk and Stuuupidd\n",
      "0                     ah to be fat drunk and Stuuupidd\n",
      "0                     ah to be fat drunk and Stuuupidd\n",
      "0                       because you are that Stuuupidd\n",
      "0                       because you are that Stuuupidd\n",
      "0                       because you are that Stuuupidd\n",
      "0    if you are not a socialist in your you have no...\n",
      "0    if you are not a socialist in your you have no...\n",
      "0    if you are not a socialist in your you have no...\n",
      "0                                         KIL the rail\n",
      "0                                         KIL the rail\n",
      "0                                         KIL the rail\n",
      "0    it is better to be handsome rich and smart tha...\n",
      "0    it is better to be handsome rich and smart tha...\n",
      "0    it is better to be handsome rich and smart tha...\n",
      "0                                        suckkkk it up\n",
      "0                                          SUUCK it up\n",
      "Name: perturbed, dtype: object\n",
      "0    there are some incredibly stupid people on thi...\n",
      "0    there are some incredibly stupid people on thi...\n",
      "0    there are some incredibly stupid people on thi...\n",
      "0                              thats just plain stupid\n",
      "0                              thats just plain stupid\n",
      "0                              thats just plain stupid\n",
      "0    typical empty stupid reply based on hate over ...\n",
      "0    typical empty stupid reply based on hate over ...\n",
      "0    typical empty stupid reply based on hate over ...\n",
      "0                   i always knew you were a dirty cop\n",
      "0                   i always knew you were a dirty cop\n",
      "0                   i always knew you were a dirty cop\n",
      "0                    dumb response off topic as always\n",
      "0                    dumb response off topic as always\n",
      "0                    dumb response off topic as always\n",
      "0                   i damn no one they damn themselves\n",
      "0                   i damn no one they damn themselves\n",
      "0                   i damn no one they damn themselves\n",
      "0    wow that is a whole of stupid and ugly that sh...\n",
      "0    wow that is a whole of stupid and ugly that sh...\n",
      "0    wow that is a whole of stupid and ugly that sh...\n",
      "0    and you lost the cold war wow my response is a...\n",
      "0    and you lost the cold war wow my response is a...\n",
      "0    and you lost the cold war wow my response is a...\n",
      "0                                  you cant fix stupid\n",
      "0                                  you cant fix stupid\n",
      "0                                  you cant fix stupid\n",
      "0                               damn you beat me to it\n",
      "0                               damn you beat me to it\n",
      "0                               damn you beat me to it\n",
      "0    good job tracker without snow the guy might ne...\n",
      "0    good job tracker without snow the guy might ne...\n",
      "0    good job tracker without snow the guy might ne...\n",
      "0                        ah to be fat drunk and stupid\n",
      "0                        ah to be fat drunk and stupid\n",
      "0                        ah to be fat drunk and stupid\n",
      "0                          because you are that stupid\n",
      "0                          because you are that stupid\n",
      "0                          because you are that stupid\n",
      "0    if you are not a socialist in your you have no...\n",
      "0    if you are not a socialist in your you have no...\n",
      "0    if you are not a socialist in your you have no...\n",
      "0                                        kill the rail\n",
      "0                                        kill the rail\n",
      "0                                        kill the rail\n",
      "0    it is better to be handsome rich and smart tha...\n",
      "0    it is better to be handsome rich and smart tha...\n",
      "0    it is better to be handsome rich and smart tha...\n",
      "0                                           suck it up\n",
      "0                                           suck it up\n",
      "Name: clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('bert_0.5_final_3.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "type(data)\n",
    "# display(data)\n",
    "print(data['perturbed'].head(50))\n",
    "print(data['clean'].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1393, 45)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def locate_pert(row):\n",
    "    # print(row)\n",
    "    c,p = row['clean'].split(), row['perturbed'].split()\n",
    "    for i in range(len(c)):\n",
    "        if c[i] != p[i]:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "distinct_data = data[data['toxicity'] > 0.5].drop_duplicates()\n",
    "distinct_data['location'] = distinct_data.apply(locate_pert,axis=1)\n",
    "distinct_data = distinct_data.drop(['perturbed'], axis=1).drop_duplicates()\n",
    "print(distinct_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perspective_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_cache_copy={k[0]:v for k,v in perspective_cache.items()}\n",
    "perspective_cache = perspective_cache_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from googleapiclient import discovery\n",
    "from serpapi import GoogleSearch\n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "API_KEY = 'XXXXXXX'\n",
    "\n",
    "client = discovery.build(\n",
    "    \"commentanalyzer\",\n",
    "    \"v1alpha1\",\n",
    "    developerKey=API_KEY,\n",
    "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "    static_discovery=False,\n",
    ")\n",
    "\n",
    "def perspective_acc(data,t=0.7):\n",
    "    denominator = [0,0,0,0] #acc_num_of_clean_perspective, acc_num_of_pert_perspective, acc_num_of_cor_perspective_languageTool, acc_num_of_cor_perspective_Google\n",
    "    acc_num_of_lt = 0\n",
    "    acc_num_of_google = 0\n",
    "    total = 0\n",
    "    for idx,row in data.iterrows():\n",
    "        time.sleep(2)\n",
    "        total += 1\n",
    "        print(total)\n",
    "        sentence_clean = row['Answer.clean']\n",
    "        sentence_pert = row['Answer.perturbed']\n",
    "        sentences = [sentence_clean,sentence_pert]\n",
    "        # print(sentences)\n",
    "\n",
    "\n",
    "        for i,sentence in enumerate(sentences):\n",
    "            analyze_request = {\n",
    "                'comment': { 'text': sentence },\n",
    "                'requestedAttributes': {'TOXICITY': {}},\n",
    "                'languages': [\"en\"],\n",
    "                'doNotStore':True\n",
    "            }\n",
    "            \n",
    "            response = client.comments().analyze(body=analyze_request).execute()\n",
    "            score = 0 if response[\"attributeScores\"][\"TOXICITY\"][\"spanScores\"][0][\"score\"][\"value\"] < t else 1\n",
    "            \n",
    "            if score:\n",
    "                denominator[i] += 1\n",
    "    \n",
    "    # print(f\"Perspective API Performance for Clean Sentence: {round(denominator[0]/total,2)}\")\n",
    "    # print(f\"Perspective API Performance for Perturbed Sentence: {round(denominator[1]/total,2)}\")\n",
    "    return f\"clean: {round(denominator[0]/total,2)}; perturb: {round(denominator[1]/total,2)}\"\n",
    "    # break\n",
    "\n",
    "def google_correct(data):\n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    for idx,row in data.iterrows():\n",
    "        time.sleep(1)\n",
    "        total += 1\n",
    "        perturbed = row['Answer.perturbed']\n",
    "        clean = row['Answer.clean']\n",
    "        print(perturbed,clean)\n",
    "        params = {\n",
    "            \"q\": perturbed,\n",
    "            \"hl\": \"en\",\n",
    "            \"gl\": \"us\",\n",
    "            \"api_key\": \"XXXXXXXX\"\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()\n",
    "        corrected = results.get('search_information', {}).get('spelling_fix',perturbed)\n",
    "        if corrected == clean:\n",
    "            cnt += 1\n",
    "    return f\"cnt: {cnt}; perturb: {round(cnt/total,2)}\"\n",
    "\n",
    "\n",
    "def perspective_api(row, t=0.7,col_name='Answer.perturbed'):\n",
    "    sentence = row[col_name]\n",
    "    if not sentence in perspective_cache:\n",
    "        time.sleep(2)\n",
    "        analyze_request = {\n",
    "                    'comment': { 'text': sentence },\n",
    "                    'requestedAttributes': {'TOXICITY': {}},\n",
    "                    'languages': [\"en\"],\n",
    "                    'doNotStore':True\n",
    "                }\n",
    "        \n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "        perspective_cache[sentence] = response[\"attributeScores\"][\"TOXICITY\"][\"spanScores\"][0][\"score\"][\"value\"]\n",
    "    return perspective_cache[sentence]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "how are you\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "perturbed = \"how areeee you\"\n",
    "clean = \"how are you\"\n",
    "# print(self.sentence)\n",
    "params = {\n",
    "    \"q\": perturbed,\n",
    "    \"hl\": \"en\",\n",
    "    \"gl\": \"us\",\n",
    "    \"api_key\": \"xxxxxxx\"\n",
    "}\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "search_information = results.get('search_information', {})\n",
    "print(search_information.get('spelling_fix', perturbed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dirtyyyy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('data/hard_pert.json') as json_file:\n",
    "    hard_pert = json.load(json_file)\n",
    "hard_pert['dirty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>perturbed</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you really need to kill yourself</td>\n",
       "      <td>you really need to ki11 yourself</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you really need to kill yourself</td>\n",
       "      <td>you really need to ki11 yourself</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and luke stay out son of a bitch</td>\n",
       "      <td>and luke stay out son of a biiiitch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dude this guy is so gay</td>\n",
       "      <td>dude this guy is so GAYYYY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am going to hack your dick account</td>\n",
       "      <td>i am going to hack your dicckkk account</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oh i yeah i feel like an ass now</td>\n",
       "      <td>oh i yeah i feel like an ASSSSS now</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>they still cant fill a full bag of suck</td>\n",
       "      <td>they still cant fill a full bag of such</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thats just plain stupid</td>\n",
       "      <td>thats just plain styled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dumb response off topic as always</td>\n",
       "      <td>dump response off topic as always</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>damn you beat me to it</td>\n",
       "      <td>dawn you beat me to it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>why you a son of a b</td>\n",
       "      <td>why you a soon of a b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clean  \\\n",
       "0          you really need to kill yourself   \n",
       "1          you really need to kill yourself   \n",
       "2          and luke stay out son of a bitch   \n",
       "3                   dude this guy is so gay   \n",
       "4      i am going to hack your dick account   \n",
       "5          oh i yeah i feel like an ass now   \n",
       "6   they still cant fill a full bag of suck   \n",
       "7                   thats just plain stupid   \n",
       "8         dumb response off topic as always   \n",
       "9                    damn you beat me to it   \n",
       "10                     why you a son of a b   \n",
       "\n",
       "                                  perturbed rating  \n",
       "0          you really need to ki11 yourself      5  \n",
       "1          you really need to ki11 yourself      5  \n",
       "2       and luke stay out son of a biiiitch      5  \n",
       "3                dude this guy is so GAYYYY      5  \n",
       "4   i am going to hack your dicckkk account      5  \n",
       "5       oh i yeah i feel like an ASSSSS now      5  \n",
       "6   they still cant fill a full bag of such      1  \n",
       "7                   thats just plain styled      1  \n",
       "8         dump response off topic as always      1  \n",
       "9                    dawn you beat me to it      1  \n",
       "10                    why you a soon of a b      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "control = pd.DataFrame(data=None, columns=data.columns)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'you really need to kill yourself', 'perturbed': 'you really need to ki11 yourself', 'rating':5}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'you really need to kill yourself', 'perturbed': 'you really need to ki11 yourself', 'rating':5}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'and luke stay out son of a bitch', 'perturbed': 'and luke stay out son of a biiiitch', 'rating':5}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'dude this guy is so gay', 'perturbed': 'dude this guy is so GAYYYY', 'rating':5}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'i am going to hack your dick account', 'perturbed': 'i am going to hack your dicckkk account', 'rating':5}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'oh i yeah i feel like an ass now', 'perturbed': 'oh i yeah i feel like an ASSSSS now', 'rating':5}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'they still cant fill a full bag of suck', 'perturbed': 'they still cant fill a full bag of such', 'rating':1}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'thats just plain stupid', 'perturbed': 'thats just plain styled', 'rating':1}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'dumb response off topic as always', 'perturbed': 'dump response off topic as always', 'rating':1}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'damn you beat me to it', 'perturbed': 'dawn you beat me to it', 'rating':1}, index=[0])], ignore_index=True)\n",
    "control = pd.concat([control, pd.DataFrame({'clean': 'why you a son of a b', 'perturbed': 'why you a soon of a b', 'rating':1}, index=[0])], ignore_index=True)\n",
    "# print(control.dtypes)\n",
    "control[['clean', 'perturbed','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 45)\n",
      "(204, 45)\n",
      "(204, 45)\n",
      "(204, 45)\n",
      "(204, 45)\n",
      "(203, 45)\n",
      "(203, 45)\n",
      "(203, 45)\n",
      "(203, 45)\n",
      "(203, 45)\n",
      "(203, 45)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "batch_size = 11\n",
    "data = data[data['toxicity'] > 0.5].drop_duplicates()\n",
    "nparr = np.array_split(data, batch_size)\n",
    "for i in range(batch_size):\n",
    "    # cur = pd.concat([nparr[i], control], ignore_index=True)\n",
    "    cur = nparr[i]\n",
    "    cur.to_csv(f\"data/mturk_batch/batch_{i}_raw.csv\", index=False)\n",
    "    print(cur.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_cache = {}\n",
    "bing_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "    \n",
    "# Data to be written\n",
    "    \n",
    "with open(\"data/google_cache.json\", \"w\") as outfile:\n",
    "    json.dump(list(google_cache.items()), outfile)\n",
    "with open(\"data/bing_cache.json\", \"w\") as outfile:\n",
    "    json.dump(list(bing_cache.items()), outfile)\n",
    "with open(\"data/perspective_cache.json\", \"w\") as outfile:\n",
    "    json.dump(list(perspective_cache.items()), outfile)\n",
    "\n",
    "\n",
    "# load\n",
    "# with open(\"file.json\",\"r\") as f:\n",
    "#     your_dict = dict([tuple((tuple(x[0]), x[1])) for x in json.loads(f.read())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(1060, 84)\n",
      "(10600, 84)\n",
      "(10600, 88)\n",
      "(7701, 88)\n",
      "(1927, 9)\n",
      "(1329, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer.clean</th>\n",
       "      <th>Answer.perturbed</th>\n",
       "      <th>location</th>\n",
       "      <th>distance</th>\n",
       "      <th>pert_word</th>\n",
       "      <th>quality_mean</th>\n",
       "      <th>quality_min</th>\n",
       "      <th>quality_max</th>\n",
       "      <th>quality_cnt</th>\n",
       "      <th>google_correct_word</th>\n",
       "      <th>google_correct_sentence</th>\n",
       "      <th>google_correct</th>\n",
       "      <th>bing_correct_word</th>\n",
       "      <th>bing_correct_sentence</th>\n",
       "      <th>bing_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a bullet to the head dude</td>\n",
       "      <td>a bULLeT to the head dude</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bULLeT</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>bullet</td>\n",
       "      <td>a bullet to the head dude</td>\n",
       "      <td>1</td>\n",
       "      <td>bullet</td>\n",
       "      <td>a bullet to the head dude</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a controversial rat</td>\n",
       "      <td>a controversial Ratt</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ratt</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>ratt</td>\n",
       "      <td>a controversial ratt</td>\n",
       "      <td>0</td>\n",
       "      <td>ratt</td>\n",
       "      <td>a controversial ratt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a fast meaningless death is exactly what the e...</td>\n",
       "      <td>a fast meaningless deth is exactly what the ev...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>deth</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>death</td>\n",
       "      <td>a fast meaningless death is exactly what the e...</td>\n",
       "      <td>1</td>\n",
       "      <td>death</td>\n",
       "      <td>a fast meaningless death is exactly what the e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a fool and his money</td>\n",
       "      <td>a fol and his money</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fol</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>fool</td>\n",
       "      <td>a fool and his money</td>\n",
       "      <td>1</td>\n",
       "      <td>fool</td>\n",
       "      <td>a fool and his money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a fool and our money are soon to be parted</td>\n",
       "      <td>a foool and our money are soon to be parted</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>foool</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>fool</td>\n",
       "      <td>a fool and our money are soon to be parted</td>\n",
       "      <td>1</td>\n",
       "      <td>fool</td>\n",
       "      <td>a fool and our money are soon to be parted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>your racist stereotyping is disgusting</td>\n",
       "      <td>your racist stereotyping is DisguSTING</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>DisguSTING</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>disgusting</td>\n",
       "      <td>your racist stereotyping is disgusting</td>\n",
       "      <td>1</td>\n",
       "      <td>disgusting</td>\n",
       "      <td>your racist stereotyping is disgusting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>your talking out of your behind</td>\n",
       "      <td>your talking out of your bEhInD</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>bEhInD</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>behind</td>\n",
       "      <td>your talking out of your behind</td>\n",
       "      <td>1</td>\n",
       "      <td>behind</td>\n",
       "      <td>your talking out of your behind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>your vote was extremely based on stupidity</td>\n",
       "      <td>your vote was extremely based on stupdity</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>stupdity</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>stupidity</td>\n",
       "      <td>your vote was extremely based on stupidity</td>\n",
       "      <td>1</td>\n",
       "      <td>stupidity</td>\n",
       "      <td>your vote was extremely based on stupidity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>youve got a gun time to get shot stop resisting</td>\n",
       "      <td>youve got a gun time to get SHooT stop resisting</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>SHooT</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>shot</td>\n",
       "      <td>youve got a gun time to get shot stop resisting</td>\n",
       "      <td>1</td>\n",
       "      <td>shoot</td>\n",
       "      <td>youve got a gun time to get shoot stop resisting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>youve got a lot to learn doubtful if you have ...</td>\n",
       "      <td>youve got a lot to learn doubtful if you have ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>sUUck</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>stuck</td>\n",
       "      <td>youve got a lot to learn doubtful if you have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>suuck</td>\n",
       "      <td>youve got a lot to learn doubtful if you have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1329 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Answer.clean  \\\n",
       "0                             a bullet to the head dude   \n",
       "1                                   a controversial rat   \n",
       "2     a fast meaningless death is exactly what the e...   \n",
       "3                                  a fool and his money   \n",
       "4            a fool and our money are soon to be parted   \n",
       "...                                                 ...   \n",
       "1921             your racist stereotyping is disgusting   \n",
       "1923                    your talking out of your behind   \n",
       "1924         your vote was extremely based on stupidity   \n",
       "1925    youve got a gun time to get shot stop resisting   \n",
       "1926  youve got a lot to learn doubtful if you have ...   \n",
       "\n",
       "                                       Answer.perturbed  location  distance  \\\n",
       "0                             a bULLeT to the head dude         1         0   \n",
       "1                                  a controversial Ratt         2         1   \n",
       "2     a fast meaningless deth is exactly what the ev...         3         1   \n",
       "3                                   a fol and his money         1         1   \n",
       "4           a foool and our money are soon to be parted         1         1   \n",
       "...                                                 ...       ...       ...   \n",
       "1921             your racist stereotyping is DisguSTING         4         0   \n",
       "1923                    your talking out of your bEhInD         5         0   \n",
       "1924          your vote was extremely based on stupdity         6         1   \n",
       "1925   youve got a gun time to get SHooT stop resisting         7         1   \n",
       "1926  youve got a lot to learn doubtful if you have ...        14         1   \n",
       "\n",
       "       pert_word  quality_mean  quality_min  quality_max  quality_cnt  \\\n",
       "0         bULLeT      3.800000            3            4            5   \n",
       "1           Ratt      3.333333            3            4            3   \n",
       "2           deth      4.000000            3            5            3   \n",
       "3            fol      3.600000            2            5            5   \n",
       "4          foool      3.500000            2            5            4   \n",
       "...          ...           ...          ...          ...          ...   \n",
       "1921  DisguSTING      4.250000            4            5            4   \n",
       "1923      bEhInD      4.400000            4            5            5   \n",
       "1924    stupdity      4.000000            3            5            5   \n",
       "1925       SHooT      3.800000            2            5            5   \n",
       "1926       sUUck      3.250000            2            4            4   \n",
       "\n",
       "     google_correct_word                            google_correct_sentence  \\\n",
       "0                 bullet                          a bullet to the head dude   \n",
       "1                   ratt                               a controversial ratt   \n",
       "2                  death  a fast meaningless death is exactly what the e...   \n",
       "3                   fool                               a fool and his money   \n",
       "4                   fool         a fool and our money are soon to be parted   \n",
       "...                  ...                                                ...   \n",
       "1921          disgusting             your racist stereotyping is disgusting   \n",
       "1923              behind                    your talking out of your behind   \n",
       "1924           stupidity         your vote was extremely based on stupidity   \n",
       "1925                shot    youve got a gun time to get shot stop resisting   \n",
       "1926               stuck  youve got a lot to learn doubtful if you have ...   \n",
       "\n",
       "      google_correct bing_correct_word  \\\n",
       "0                  1            bullet   \n",
       "1                  0              ratt   \n",
       "2                  1             death   \n",
       "3                  1              fool   \n",
       "4                  1              fool   \n",
       "...              ...               ...   \n",
       "1921               1        disgusting   \n",
       "1923               1            behind   \n",
       "1924               1         stupidity   \n",
       "1925               1             shoot   \n",
       "1926               0             suuck   \n",
       "\n",
       "                                  bing_correct_sentence  bing_correct  \n",
       "0                             a bullet to the head dude             1  \n",
       "1                                  a controversial ratt             0  \n",
       "2     a fast meaningless death is exactly what the e...             1  \n",
       "3                                  a fool and his money             1  \n",
       "4            a fool and our money are soon to be parted             1  \n",
       "...                                                 ...           ...  \n",
       "1921             your racist stereotyping is disgusting             1  \n",
       "1923                    your talking out of your behind             1  \n",
       "1924         your vote was extremely based on stupidity             1  \n",
       "1925   youve got a gun time to get shoot stop resisting             0  \n",
       "1926  youve got a lot to learn doubtful if you have ...             0  \n",
       "\n",
       "[1329 rows x 15 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import requests\n",
    "\n",
    "\n",
    "def locate_pert(row):\n",
    "    # print(row)\n",
    "    c,p = row['Answer.clean'].split(), row['Answer.perturbed'].split()\n",
    "    for i in range(len(c)):\n",
    "        if c[i] != p[i]:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def distance(row):\n",
    "    l = row['location']\n",
    "    c,p = row['Answer.clean'].split()[l], row['Answer.perturbed'].split()[l]\n",
    "    return Levenshtein.distance(c.lower(),p.lower())\n",
    "\n",
    "\n",
    "def show_pert(row):\n",
    "    l = row['location']\n",
    "    return row['Answer.perturbed'].split()[l]\n",
    "\n",
    "\n",
    "def google_api(perturbed_sentence, clean_sentence, l):\n",
    "    if (perturbed_sentence, clean_sentence, l) in google_cache:\n",
    "        return google_cache[(perturbed_sentence, clean_sentence, l)]\n",
    "    params = {\n",
    "        \"q\": perturbed_sentence,\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"us\",\n",
    "        \"api_key\": \"xxxxxx\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    corrected = results.get('search_information', {}).get('spelling_fix',perturbed_sentence)\n",
    "    if len(corrected.split()) > l and corrected.split()[l].lower() == clean_sentence.split()[l].lower():\n",
    "        google_cache[(perturbed_sentence, clean_sentence, l)] = (corrected.split()[l].lower(),1)\n",
    "    else:\n",
    "        google_cache[(perturbed_sentence, clean_sentence, l)] = (corrected.split()[l].lower(),0) if len(corrected.split()) > l else (corrected,0)\n",
    "    return google_cache[(perturbed_sentence, clean_sentence, l)]\n",
    "        \n",
    "\n",
    "\n",
    "def bing_api(perturbed_sentence, clean_sentence, l):\n",
    "    if (perturbed_sentence, clean_sentence, l) in bing_cache:\n",
    "        return bing_cache[(perturbed_sentence, clean_sentence, l)]\n",
    "    corrected = perturbed_sentence\n",
    "    api_key = \"xxxxx\"\n",
    "    endpoint = \"https://api.bing.microsoft.com/v7.0/spellcheck\"\n",
    "    data = {'text': perturbed_sentence}\n",
    "    params = {\n",
    "    'mkt':'en-us',\n",
    "    'mode':'proof'\n",
    "    }\n",
    "    headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Ocp-Apim-Subscription-Key': api_key,\n",
    "    }\n",
    "    response = requests.post(endpoint, headers=headers, params=params, data=data)\n",
    "    for e in response.json().get('flaggedTokens', []):\n",
    "        if 'token' in e and 'suggestions' in e and e['suggestions']:\n",
    "            corrected = corrected.replace(e['token'], e['suggestions'][0]['suggestion'])\n",
    "    if len(corrected.split()) > l and corrected.split()[l].lower() == clean_sentence.split()[l].lower():\n",
    "        # print(corrected.split()[l].lower(),1)\n",
    "        bing_cache[(perturbed_sentence, clean_sentence, l)] = (corrected.split()[l].lower(),1)\n",
    "    else:\n",
    "        bing_cache[(perturbed_sentence, clean_sentence, l)] = (corrected.split()[l].lower(),0) if len(corrected.split()) > l else (corrected,0)\n",
    "    return bing_cache[(perturbed_sentence, clean_sentence, l)]\n",
    "\n",
    "\n",
    "def api_correct(row,func=google_api):\n",
    "    perturbed_sentence, clean_sentence, l = row['Answer.perturbed'], row['Answer.clean'], row['location']\n",
    "    result, correct = func(perturbed_sentence, clean_sentence, l)\n",
    "    result_sentence_list = clean_sentence.split()\n",
    "    result_sentence_list[l] = result\n",
    "    return pd.Series([result, ' '.join(result_sentence_list), correct])\n",
    "\n",
    "\n",
    "df_batch_0 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4978329_batch_results.csv')\n",
    "print(df_batch_0.shape)\n",
    "df_batch_1 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4979170_batch_results.csv')\n",
    "print(df_batch_1.shape)\n",
    "df_batch_2 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4979419_batch_results.csv')\n",
    "print(df_batch_2.shape)\n",
    "df_batch_3 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4981951_batch_results.csv')\n",
    "print(df_batch_3.shape)\n",
    "df_batch_4 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4979863_batch_results.csv')\n",
    "print(df_batch_4.shape)\n",
    "df_batch_5 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4979911_batch_results.csv')\n",
    "print(df_batch_5.shape)\n",
    "df_batch_6 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4980383_batch_results.csv')\n",
    "print(df_batch_6.shape)\n",
    "df_batch_7 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4980585_batch_results.csv')\n",
    "print(df_batch_7.shape)\n",
    "df_batch_8 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4981021_batch_results.csv')\n",
    "print(df_batch_8.shape)\n",
    "df_batch_9 = pd.read_csv('data/mturk_batch/mturk_result/Batch_4981364_batch_results.csv')\n",
    "print(df_batch_9.shape)\n",
    "\n",
    "# df = pd.concat([df_batch_0, df_batch_1, df_batch_2, df_batch_3, df_batch_4, df_batch_5, df_batch_6, df_batch_7], ignore_index=True)\n",
    "\n",
    "df = pd.concat([df_batch_0, df_batch_1, df_batch_2, df_batch_3, df_batch_4, df_batch_5, df_batch_6, df_batch_7, df_batch_8, df_batch_9], ignore_index=True)\n",
    "print(df.shape)\n",
    "\n",
    "df['quality'] = df.apply(lambda row: 1 if row['Answer.Very unlikely.1'] else 2 if row['Answer.Unlikely.2'] else 3 if row['Answer.Fair.3'] else 4 if row['Answer.Likely.4'] else 5, axis=1)\n",
    "df['location'] = df.apply(locate_pert,axis=1)\n",
    "df['distance'] = df.apply(distance,axis=1)\n",
    "df['pert_word'] = df.apply(show_pert,axis=1)\n",
    "print(df.shape)\n",
    "df = df[df[\"Answer.pert_location\"] == df['location']]\n",
    "df = df[df[\"Input.toxicity\"] > 0.5]\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "tagged_df = df[['Answer.clean','Answer.perturbed','quality','Answer.time_spent','location', 'distance', 'pert_word']]\n",
    "\n",
    "grouped_multiple = tagged_df.groupby(['Answer.clean', 'Answer.perturbed', 'location', 'distance', 'pert_word']).agg({'quality': ['mean', 'min', 'max', 'count']})\n",
    "grouped_multiple.columns = ['quality_mean', 'quality_min', 'quality_max', 'quality_cnt']\n",
    "grouped_multiple = grouped_multiple.reset_index()\n",
    "print(grouped_multiple.shape)\n",
    "grouped_multiple = grouped_multiple[grouped_multiple[\"quality_cnt\"] >= 3]\n",
    "grouped_multiple = grouped_multiple[grouped_multiple[\"quality_mean\"] > 3]\n",
    "print(grouped_multiple.shape)\n",
    "\n",
    "grouped_multiple[['google_correct_word','google_correct_sentence','google_correct']] = grouped_multiple.apply(api_correct, args=(google_api,), axis=1)\n",
    "grouped_multiple[['bing_correct_word','bing_correct_sentence','bing_correct']] = grouped_multiple.apply(api_correct, args=(bing_api,), axis=1)\n",
    "\n",
    "\n",
    "grouped_multiple\n",
    "\n",
    "# df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perspective_result_on_pert acc:  0.671933784800602\n",
      "perspective_result_on_clean acc:  0.8141459744168548\n",
      "perspective_result_on_bing_correct acc:  0.7223476297968398\n",
      "perspective_result_on_google_correct acc:  0.7268623024830699\n"
     ]
    }
   ],
   "source": [
    "grouped_multiple['perspective_result_on_pert'] = grouped_multiple.apply(perspective_api, args=(0.5,'Answer.perturbed'), axis=1)\n",
    "grouped_multiple['perspective_result_on_clean'] = grouped_multiple.apply(perspective_api, args=(0.5,'Answer.clean'), axis=1)\n",
    "grouped_multiple['perspective_result_on_bing_correct'] = grouped_multiple.apply(perspective_api, args=(0.5,'bing_correct_sentence'), axis=1)\n",
    "grouped_multiple['perspective_result_on_google_correct'] = grouped_multiple.apply(perspective_api, args=(0.5,'google_correct_sentence'), axis=1)\n",
    "# grouped_multiple['perspective_result_on_spell_correct'] = grouped_multiple.apply(perspective_api, args=(0.5,'spell_correct_sentence'), axis=1)\n",
    "# grouped_multiple['perspective_result_on_neu_correct'] = grouped_multiple.apply(perspective_api, args=(0.5,'neu_correct_sentence'), axis=1)\n",
    "print(\"perspective_result_on_pert acc: \", grouped_multiple[grouped_multiple[\"perspective_result_on_pert\"] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "print(\"perspective_result_on_clean acc: \", grouped_multiple[grouped_multiple[\"perspective_result_on_clean\"] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "print(\"perspective_result_on_bing_correct acc: \", grouped_multiple[grouped_multiple[\"perspective_result_on_bing_correct\"] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "print(\"perspective_result_on_google_correct acc: \", grouped_multiple[grouped_multiple[\"perspective_result_on_google_correct\"] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "# print(\"perspective_result_on_spell_correct acc: \", grouped_multiple[\"perspective_result_on_spell_correct\"].mean())\n",
    "# print(\"perspective_result_on_neu_correct acc: \", grouped_multiple[\"perspective_result_on_neu_correct\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 1.0\n",
      "0.05 0.998 1.0\n",
      "0.1 0.994 1.0\n",
      "0.15 0.987 1.0\n",
      "0.2 0.983 1.0\n",
      "0.25 0.977 1.0\n",
      "0.3 0.956 0.996\n",
      "0.35 0.924 0.99\n",
      "0.4 0.875 0.965\n",
      "0.45 0.792 0.916\n",
      "0.5 0.672 0.814\n",
      "0.55 0.547 0.681\n",
      "0.6 0.389 0.525\n",
      "0.65 0.254 0.363\n",
      "0.7 0.175 0.26\n",
      "0.75 0.126 0.204\n",
      "0.8 0.07 0.114\n",
      "0.85 0.04 0.072\n",
      "0.9 0.01 0.019\n",
      "0.95 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "t_generator = (round(x * 0.05,2) for x in range(0, 20))\n",
    "for t in t_generator:\n",
    "    print(t,round(grouped_multiple[grouped_multiple[\"perspective_result_on_pert\"] > t].shape[0] / grouped_multiple.shape[0],3),round(grouped_multiple[grouped_multiple[\"perspective_result_on_clean\"] > t].shape[0] / grouped_multiple.shape[0],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_multiple = grouped_multiple[~grouped_multiple['pert_word'].isin(['STUPIDDDDD','stupiddddd','Stuuupidd','stpd'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google acc:  0.7550173010380623\n",
      "bing acc:  0.6325259515570935\n",
      "spell checker acc:  0.7280276816608997\n",
      "neu acc:  0.5826989619377163\n"
     ]
    }
   ],
   "source": [
    "print(\"google acc: \", grouped_multiple[\"google_correct\"].mean())\n",
    "print(\"bing acc: \", grouped_multiple[\"bing_correct\"].mean())\n",
    "print(\"spell checker acc: \", grouped_multiple[\"spell_correct\"].mean())\n",
    "print(\"neu acc: \", grouped_multiple[\"neu_correct\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_multiple.to_csv('grouped_multiple.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">google_correct</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bing_correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759259</td>\n",
       "      <td>54</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.418182</td>\n",
       "      <td>55</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818841</td>\n",
       "      <td>138</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.831731</td>\n",
       "      <td>208</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         google_correct       bing_correct      \n",
       "                   mean count         mean count\n",
       "distance                                        \n",
       "1              0.759259    54     0.240741    54\n",
       "2              0.418182    55     0.127273    55\n",
       "3              0.818841   138     0.050725   138\n",
       "4              0.831731   208     0.019231   208\n",
       "5              0.300000    30     0.066667    30"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_vs_acc_df = grouped_multiple.groupby(['distance']).agg({'google_correct': ['mean', 'count'],'bing_correct': ['mean', 'count']})\n",
    "distance_vs_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pert_word  google_mean  google_cnt  bing_mean  bing_cnt\n",
      "63   TRRAAASSHH     1.000000           2   0.500000         2\n",
      "59     Shooooot     1.000000           1   1.000000         1\n",
      "80   crazyyyyyy     1.000000           1   0.000000         1\n",
      "78         blCK     1.000000           2   1.000000         2\n",
      "77   bitcccccch     1.000000           1   0.000000         1\n",
      "76    biiitchhh     1.000000           1   0.000000         1\n",
      "73        baddd     1.000000           1   1.000000         1\n",
      "72      baaaaad     1.000000           1   0.000000         1\n",
      "65      UGGGGLY     1.000000           1   0.000000         1\n",
      "64    Trashhhhh     1.000000           1   0.000000         1\n",
      "58    Shoooooot     1.000000           1   0.000000         1\n",
      "82   crrrrazzyy     1.000000           1   1.000000         1\n",
      "53        PIGGG     1.000000           1   0.000000         1\n",
      "52         Nutt     1.000000           1   0.000000         1\n",
      "51         NUTT     1.000000           1   0.000000         1\n",
      "50         Lett     1.000000           1   1.000000         1\n",
      "49          Kil     1.000000           7   0.000000         7\n",
      "48          KIL     1.000000           4   0.000000         4\n",
      "47         ILLL     1.000000           1   0.000000         1\n",
      "46     Hellllll     1.000000           2   0.000000         2\n",
      "81   crrazzzyyy     1.000000           1   0.000000         1\n",
      "86      deaaadd     1.000000           1   1.000000         1\n",
      "44          Hel     1.000000           1   0.000000         1\n",
      "103          iL     1.000000           1   1.000000         1\n",
      "125     ugglyyy     1.000000           1   0.000000         1\n",
      "123   trashhhhh     1.000000           3   0.000000         3\n",
      "121    traaaash     1.000000           3   0.666667         3\n",
      "115    sickkkkk     1.000000           1   0.000000         1\n",
      "110     shuuutt     1.000000           2   1.000000         2\n",
      "109        sh_t     1.000000           1   1.000000         1\n",
      "105        nutt     1.000000           1   0.000000         1\n",
      "104          il     1.000000           1   1.000000         1\n",
      "101    hellllll     1.000000           1   0.000000         1\n",
      "87      deadddd     1.000000           1   1.000000         1\n",
      "100         hel     1.000000           1   0.000000         1\n",
      "99       fireee     1.000000           1   0.000000         1\n",
      "97      fattttt     1.000000           1   0.000000         1\n",
      "96         fatt     1.000000           1   1.000000         1\n",
      "95      faaaaat     1.000000           1   0.000000         1\n",
      "94     faaaaaat     1.000000           1   0.000000         1\n",
      "92     dirtyyyy     1.000000           5   0.000000         5\n",
      "88     deaddddd     1.000000           1   0.000000         1\n",
      "45      Helllll     1.000000           2   0.000000         2\n",
      "126     uglyyyy     1.000000           1   0.000000         1\n",
      "43          HeL     1.000000           2   0.000000         2\n",
      "42     HELLLLLL     1.000000           2   0.000000         2\n",
      "32         Fatt     1.000000           1   1.000000         1\n",
      "33       GAYYYY     1.000000           2   0.000000         2\n",
      "7      Baaaaaad     1.000000           1   0.000000         1\n",
      "8          Blck     1.000000           3   1.000000         3\n",
      "10    CRAZZZYYY     1.000000           1   0.000000         1\n",
      "11    Crraazzyy     1.000000           1   1.000000         1\n",
      "35      GOOOOOD     1.000000           1   0.000000         1\n",
      "31         FATT     1.000000           1   0.000000         1\n",
      "36         Gass     1.000000           1   1.000000         1\n",
      "38       Gayyyy     1.000000           3   0.000000         3\n",
      "40          HEL     1.000000           2   0.000000         2\n",
      "41      HELLLLL     1.000000           1   0.000000         1\n",
      "5          BLCK     1.000000           7   0.142857         7\n",
      "20      DUMBBBB     0.863636          22   0.000000        22\n",
      "93     duuuuumb     0.800000          20   0.000000        20\n",
      "91        dieee     0.666667           3   1.000000         3\n",
      "124   trassshhh     0.666667           3   0.000000         3\n",
      "122    trashhhh     0.666667           3   0.000000         3\n",
      "62      Siiiick     0.500000           2   0.000000         2\n",
      "112   shuuuuuut     0.500000           2   0.000000         2\n",
      "16        DIEEE     0.500000           2   1.000000         2\n",
      "56     SIIICCCK     0.500000           2   0.000000         2\n",
      "111    shuuuuut     0.500000           2   0.500000         2\n",
      "113     sicckkk     0.500000           2   0.000000         2\n",
      "114     sickkkk     0.500000           2   0.000000         2\n",
      "18      DIIIICK     0.000000           1   0.000000         1\n",
      "13      DAAAAMN     0.000000           1   0.000000         1\n",
      "2      ASSSSSSS     0.000000           1   0.000000         1\n",
      "17      DIEEEEE     0.000000           3   0.000000         3\n",
      "118    suckkkkk     0.000000           4   0.000000         4\n",
      "116   sickkkkkk     0.000000           2   0.000000         2\n",
      "15      DAMNNNN     0.000000           1   0.000000         1\n",
      "3      BIIIITCH     0.000000           1   0.000000         1\n",
      "14    DAMMMMMMN     0.000000           1   0.000000         1\n",
      "98     fiiiiire     0.000000           1   0.000000         1\n",
      "12     DAAAAAMN     0.000000           1   0.000000         1\n",
      "6         BRYAN     0.000000           1   0.000000         1\n",
      "119      suuuck     0.000000           3   0.000000         3\n",
      "102   helllllll     0.000000           2   0.000000         2\n",
      "4     BITCHHHHH     0.000000           1   0.000000         1\n",
      "117     suckkkk     0.000000           3   0.000000         3\n",
      "106     raaaape     0.000000           1   0.000000         1\n",
      "107       sUUck     0.000000           3   0.000000         3\n",
      "108        shOT     0.000000           1   0.000000         1\n",
      "120   suuuuuuck     0.000000           3   0.000000         3\n",
      "9           Brn     0.000000           1   1.000000         1\n",
      "85     damnnnnn     0.000000           1   0.000000         1\n",
      "90     dickkkkk     0.000000           1   0.000000         1\n",
      "61     Shuttttt     0.000000           2   0.500000         2\n",
      "69       asssss     0.000000           1   0.000000         1\n",
      "68        assss     0.000000           1   0.000000         1\n",
      "67           as     0.000000           2   0.000000         2\n",
      "66           aS     0.000000           1   0.000000         1\n",
      "30      DiCkkkk     0.000000           1   0.000000         1\n",
      "1        ASSSSS     0.000000           1   0.000000         1\n",
      "60         Shot     0.000000           1   0.000000         1\n",
      "89      dickkkk     0.000000           1   0.000000         1\n",
      "57        SUUCK     0.000000           3   0.000000         3\n",
      "55         SHoT     0.000000           1   0.000000         1\n",
      "54    RAAAAAAPE     0.000000           1   0.000000         1\n",
      "34      GAYYYYY     0.000000           2   0.000000         2\n",
      "37      Gayayay     0.000000           1   1.000000         1\n",
      "39     Gayyyyyy     0.000000           3   0.000000         3\n",
      "70      assssss     0.000000           2   0.000000         2\n",
      "71     asssssss     0.000000           1   0.000000         1\n",
      "29    Dammmnnnn     0.000000           1   0.000000         1\n",
      "28     Dammmnnn     0.000000           1   0.000000         1\n",
      "74   biiiiiitch     0.000000           1   0.000000         1\n",
      "75     biiiitch     0.000000           1   0.000000         1\n",
      "27    Dammmmnnn     0.000000           1   0.000000         1\n",
      "26     Daaamnnn     0.000000           1   0.000000         1\n",
      "25    Daaammmnn     0.000000           1   0.000000         1\n",
      "79   craaaaaazy     0.000000           1   0.000000         1\n",
      "24      Daaaamn     0.000000           1   0.000000         1\n",
      "23     Daaaaamn     0.000000           1   0.000000         1\n",
      "22    Daaaaaamn     0.000000           1   0.000000         1\n",
      "83     dammmmmn     0.000000           1   0.000000         1\n",
      "84      dammmmn     0.000000           1   0.000000         1\n",
      "21     DaaaAAMN     0.000000           1   0.000000         1\n",
      "19     DIIIIICK     0.000000           1   0.000000         1\n",
      "0            AS     0.000000           1   0.000000         1\n"
     ]
    }
   ],
   "source": [
    "pert_word_vs_acc_df = grouped_multiple.groupby(['pert_word']).agg({'google_correct': ['mean', 'count'],'bing_correct': ['mean', 'count']})\n",
    "pert_word_vs_acc_df.columns = ['google_mean', 'google_cnt', 'bing_mean','bing_cnt']\n",
    "pert_word_vs_acc_df = pert_word_vs_acc_df.reset_index()\n",
    "pert_word_vs_acc_df = pert_word_vs_acc_df.sort_values(by='google_mean', ascending=False)\n",
    "print(pert_word_vs_acc_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: another stpd comment, clean: another stupid comment, corrected: another stpd comment\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: astonishingly DUMBBBB false equivalence here did you finish high school, clean: astonishingly dumb false equivalence here did you finish high school, corrected: astonishingly DUMBBBB false equivalence here did you finish high school\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: because he and they are stpd when it comes to understanding science, clean: because he and they are stupid when it comes to understanding science, corrected: because he and they are stpd when it comes to understanding science\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: because thats your name which i know since you told me long ago take your craaaaaazy pill don, clean: because thats your name which i know since you told me long ago take your crazy pill don, corrected: because that's your name which i know since you told me long ago take your craaaazy pill do\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: being a DIIIICK must be yours, clean: being a dick must be yours, corrected: being a DIIIICK must be yours\n",
      "https://serpapi.com/search\n",
      "pert: being a dickkkk must be yours, clean: being a dick must be yours, corrected: being a dickkkk must be yours\n",
      "https://serpapi.com/search\n",
      "pert: being a dickkkkk must be yours, clean: being a dick must be yours, corrected: being a dickkkkk must be yours\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: cant argue with stuck on stpd you cling to your opinion i will cling to mine, clean: cant argue with stuck on stupid you cling to your opinion i will cling to mine, corrected: can't argue with stuck on stpd you cling to your opinion i will cling to mine\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: charismatic flake needs to keep his stpd yap shut, clean: charismatic flake needs to keep his stupid yap shut, corrected: charismatic flake needs to keep his stpd yap shut\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: fiiiiire the trouble maker, clean: fire the trouble maker, corrected: fiiiiire the trouble maker\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: go sUUck an egg dog, clean: go suck an egg dog, corrected: go dUck an egg dog\n",
      "https://serpapi.com/search\n",
      "pert: go suckkkkk an egg dog, clean: go suck an egg dog, corrected: go suckkkkk an egg dog\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: his id is fake i hope ice is waiting for his ASSSSSSS wishful thinking of course, clean: his id is fake i hope ice is waiting for his ass wishful thinking of course, corrected: his id is fake i hope ice is waiting for his ASSSSSSS wishful thinking of course\n",
      "https://serpapi.com/search\n",
      "pert: his id is fake i hope ice is waiting for his asssssss wishful thinking of course, clean: his id is fake i hope ice is waiting for his ass wishful thinking of course, corrected: his id is fake i hope ice is waiting for his asssssss wishful thinking of course\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: how original and stpd, clean: how original and stupid, corrected: how original and stpd\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: i DAAAAMN no one they damn themselves, clean: i damn no one they damn themselves, corrected: i DAAAAAMN no one they damn themselves\n",
      "https://serpapi.com/search\n",
      "pert: i DAMMMMMMN no one they damn themselves, clean: i damn no one they damn themselves, corrected: i DAMMMMMN no one they damn themselves\n",
      "https://serpapi.com/search\n",
      "pert: i Daaaaaamn no one they damn themselves, clean: i damn no one they damn themselves, corrected: i Daaaaamn no one they damn themselves\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: i just watched it on the movie network egregious puerile trashhhh, clean: i just watched it on the movie network egregious puerile trash, corrected: i just watched it on the movie network egregious puerile trashhhh\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: if aggression and violence are part of your sexual response your a broken and SIIICCCK individual go seek help, clean: if aggression and violence are part of your sexual response your a broken and sick individual go seek help, corrected: if aggression and violence are part of your sexual response your a broken and STICK individual to seek help\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: if aggression and violence are part of your sexual response your a broken and sickkkkkk individual go seek help, clean: if aggression and violence are part of your sexual response your a broken and sick individual go seek help, corrected: if aggression and violence are part of your sexual response your a broken and sickkkkkk individual to seek help\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: it was a reply to your first post about the driver being stpd, clean: it was a reply to your first post about the driver being stupid, corrected: it was a reply to your first post about the driver being stpd\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: it was also stpd childish and inappropriate, clean: it was also stupid childish and inappropriate, corrected: it was also stpd childish and inappropriate\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: it was still a stpd comment, clean: it was still a stupid comment, corrected: it was still a stpd comment\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: its pretty stpd the bland leading the bland, clean: its pretty stupid the bland leading the bland, corrected: it's pretty stpd the bland leading the bland\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: like helllllll you are, clean: like hell you are, corrected: like helllllll you are\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: not a joke you BIIIITCH, clean: not a joke you bitch, corrected: not a joke you BIIIITCH\n",
      "https://serpapi.com/search\n",
      "pert: not a joke you biiiiiitch, clean: not a joke you bitch, corrected: not a joke you biiiiiitch\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: not if they are white GAYYYYY men, clean: not if they are white gay men, corrected: not if they are white GAYYYYY men\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: not if they are white Gayyyyyy men, clean: not if they are white gay men, corrected: not if they are white Gayyyyyy men\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: please stop this and take this extra fee off our electric bill duuuuumb idea, clean: please stop this and take this extra fee off our electric bill dumb idea, corrected: please stop this and take this extra fee off your electric bill duuuuumb idea\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: she did that right after taking from trump Daaaamn her again, clean: she did that right after taking from trump damn her again, corrected: she did that right after taking from trump Daaaamn her again\n",
      "https://serpapi.com/search\n",
      "pert: she did that right after taking from trump Daaammmnn her again, clean: she did that right after taking from trump damn her again, corrected: she did that right after taking from trump Daaammmnnn her again\n",
      "https://serpapi.com/search\n",
      "pert: she did that right after taking from trump dammmmmn her again, clean: she did that right after taking from trump damn her again, corrected: she did that right after taking from trump dammmmmn her again\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: so young and stpd, clean: so young and stupid, corrected: so young and stpd\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: stpd and counter productive, clean: stupid and counter productive, corrected: stpd and counter productive\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: stpd and regressive look it up it not, clean: stupid and regressive look it up it not, corrected: stpd and regressive look it up it not\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: stpd and shortsighted, clean: stupid and shortsighted, corrected: stpd and shortsighted\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: stpd identity politics to boot, clean: stupid identity politics to boot, corrected: stpd identity politics to boot\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: that would be just plain stpd, clean: that would be just plain stupid, corrected: that would be just plain stpd\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: they havent gotten away from the DUMBBBB part yet, clean: they havent gotten away from the dumb part yet, corrected: they haven't gotten away from the DUMBBBB part yet\n",
      "https://serpapi.com/search\n",
      "pert: they havent gotten away from the duuuuumb part yet, clean: they havent gotten away from the dumb part yet, corrected: they haven't gotten away from the duuuuumb part yet\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: well yes but if you were to DIEEEEE of murder, clean: well yes but if you were to die of murder, corrected: well yes but if you were to DIEEEEE of murder\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: what truth pizza gate you cant fix STUPIDDDDD, clean: what truth pizza gate you cant fix stupid, corrected: what truth pizzagate you can't fix STUPID DD\n",
      "https://serpapi.com/search\n",
      "pert: what truth pizza gate you cant fix Stuuupidd, clean: what truth pizza gate you cant fix stupid, corrected: what truth pizzagate you can't fix Stupid\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: wow that is a whole of stpd and ugly that should be removed from the gene pool, clean: wow that is a whole of stupid and ugly that should be removed from the gene pool, corrected: wow that is a whole of stpd and ugly that should be removed from the gene pool\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: yea that would fix stpd driving good idea, clean: yea that would fix stupid driving good idea, corrected: yeah that would fix stpd driving good idea\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: yeah mountain comes off as the perfect as, clean: yeah mountain comes off as the perfect ass, corrected: yeah mountain comes off as the perfect as\n",
      "https://serpapi.com/search\n",
      "pert: yeah mountain comes off as the perfect assssss, clean: yeah mountain comes off as the perfect ass, corrected: yeah mountain comes off as the perfect assssss\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: you know fat and stpd is no way to go through life, clean: you know fat and stupid is no way to go through life, corrected: you know fat and stpd is no way to go through life\n",
      "https://serpapi.com/search\n",
      "pert: you lost suckkkkk it up snowflake, clean: you lost suck it up snowflake, corrected: you lost suckkkkk it up snowflake\n",
      "https://serpapi.com/search\n",
      "pert: you lost suuuuuuck it up snowflake, clean: you lost suck it up snowflake, corrected: you lost suuuuuuck it up snowflake\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "https://serpapi.com/search\n",
      "pert: youve got a lot to learn doubtful if you have the capacity though must SUUCK to be you, clean: youve got a lot to learn doubtful if you have the capacity though must suck to be you, corrected: you've got a lot to learn doubtful if you have the capacity though must STUCK to be you\n",
      "https://serpapi.com/search\n",
      "pert: youve got a lot to learn doubtful if you have the capacity though must suckkkk to be you, clean: youve got a lot to learn doubtful if you have the capacity though must suck to be you, corrected: you've got a lot to learn doubtful if you have the capacity though must suckkkk to be you\n",
      "https://serpapi.com/search\n",
      "pert: youve got a lot to learn doubtful if you have the capacity though must suuuck to be you, clean: youve got a lot to learn doubtful if you have the capacity though must suck to be you, corrected: you've got a lot to learn doubtful if you have the capacity though must stuck to be you\n",
      "cnt: 192; total: 247; perturb: 0.78\n",
      "cnt: 9; total: 247; perturb: 0.04\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "def google_correct(data):\n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    for idx,row in data.iterrows():\n",
    "        time.sleep(1)\n",
    "        total += 1\n",
    "        perturbed = row['Answer.perturbed']\n",
    "        clean = row['Answer.clean']\n",
    "        params = {\n",
    "            \"q\": perturbed,\n",
    "            \"hl\": \"en\",\n",
    "            \"gl\": \"us\",\n",
    "            \"api_key\": \"xxxx\"\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()\n",
    "        corrected = results.get('search_information', {}).get('spelling_fix',perturbed)\n",
    "        # print(corrected, corrected.lower() == clean.lower())\n",
    "        if len(corrected.split()) > int(row['location']) and corrected.split()[int(row['location'])].lower() == clean.split()[int(row['location'])].lower():\n",
    "            cnt += 1\n",
    "        else:\n",
    "            print(f\"pert: {perturbed}, clean: {clean}, corrected: {corrected}\")\n",
    "    return f\"cnt: {cnt}; total: {total}; perturb: {round(cnt/total,2)}\"\n",
    "\n",
    "\n",
    "\n",
    "def bing_correct(data):\n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    for idx,row in data.iterrows():\n",
    "        time.sleep(1)\n",
    "        total += 1\n",
    "        perturbed = row['Answer.perturbed']\n",
    "        clean = row['Answer.clean']\n",
    "        corrected = perturbed\n",
    "\n",
    "        api_key = \"xxxxxxx\"\n",
    "        endpoint = \"https://api.bing.microsoft.com/v7.0/spellcheck\"\n",
    "        data = {'text': perturbed}\n",
    "\n",
    "        params = {\n",
    "        'mkt':'en-us',\n",
    "        'mode':'proof'\n",
    "        }\n",
    "        headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Ocp-Apim-Subscription-Key': api_key,\n",
    "        }\n",
    "        response = requests.post(endpoint, headers=headers, params=params, data=data)\n",
    "        # print(response.json())\n",
    "        for e in response.json().get('flaggedTokens', []):\n",
    "            if 'token' in e and 'suggestions' in e and e['suggestions']:\n",
    "                corrected = corrected.replace(e['token'], e['suggestions'][0]['suggestion'])\n",
    "        # print(corrected)\n",
    "        if len(corrected.split()) > int(row['location']) and corrected.split()[int(row['location'])].lower() == clean.split()[int(row['location'])].lower():\n",
    "            cnt += 1\n",
    "        else:\n",
    "            pass\n",
    "            # print(f\"pert: {perturbed}, clean: {clean}, corrected: {corrected}\")\n",
    "    return f\"cnt: {cnt}; total: {total}; perturb: {round(cnt/total,2)}\"\n",
    "\n",
    "\n",
    "\n",
    "# print(grouped_multiple.columns)\n",
    "print(google_correct(grouped_multiple[grouped_multiple[\"quality_mean\"] > 3]))\n",
    "print(bing_correct(grouped_multiple[grouped_multiple[\"quality_mean\"] > 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer.clean           what truth pizza gate you cant fix stupid\n",
       "Answer.perturbed    what truth pizza gate you cant fix Stuuupidd\n",
       "location                                                       7\n",
       "quality_mean                                                 3.6\n",
       "quality_min                                                    3\n",
       "quality_max                                                    4\n",
       "Name: 156, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_multiple[grouped_multiple[\"quality_mean\"] > 3].iloc[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://serpapi.com/search\n",
      "what truth pizzagate you can't fix Stupid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "    \"q\": 'what truth pizza gate you cant fix Stuuupidd',\n",
    "    \"hl\": \"en\",\n",
    "    \"gl\": \"us\",\n",
    "    \"api_key\": \"xxxxxx\"\n",
    "}\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "corrected = results.get('search_information', {}).get('spelling_fix',perturbed)\n",
    "print(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HITId</th>\n",
       "      <th>HITTypeId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Reward</th>\n",
       "      <th>CreationTime</th>\n",
       "      <th>MaxAssignments</th>\n",
       "      <th>RequesterAnnotation</th>\n",
       "      <th>AssignmentDurationInSeconds</th>\n",
       "      <th>...</th>\n",
       "      <th>Answer.clean</th>\n",
       "      <th>Answer.pert_location</th>\n",
       "      <th>Answer.perturbed</th>\n",
       "      <th>Answer.time_spent</th>\n",
       "      <th>Approve</th>\n",
       "      <th>Reject</th>\n",
       "      <th>quality</th>\n",
       "      <th>location</th>\n",
       "      <th>distance</th>\n",
       "      <th>pert_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [HITId, HITTypeId, Title, Description, Keywords, Reward, CreationTime, MaxAssignments, RequesterAnnotation, AssignmentDurationInSeconds, AutoApprovalDelayInSeconds, Expiration, NumberOfSimilarHITs, LifetimeInSeconds, AssignmentId, WorkerId, AssignmentStatus, AcceptTime, SubmitTime, AutoApprovalTime, ApprovalTime, RejectionTime, RequesterFeedback, WorkTimeInSeconds, LifetimeApprovalRate, Last30DaysApprovalRate, Last7DaysApprovalRate, Input.created_date, Input.publication_id, Input.parent_id, Input.article_id, Input.rating, Input.funny, Input.wow, Input.sad, Input.likes, Input.disagree, Input.toxicity, Input.severe_toxicity, Input.obscene, Input.sexual_explicit, Input.identity_attack, Input.insult, Input.threat, Input.male, Input.female, Input.transgender, Input.other_gender, Input.heterosexual, Input.homosexual_gay_or_lesbian, Input.bisexual, Input.other_sexual_orientation, Input.christian, Input.jewish, Input.muslim, Input.hindu, Input.buddhist, Input.atheist, Input.other_religion, Input.black, Input.white, Input.asian, Input.latino, Input.other_race_or_ethnicity, Input.physical_disability, Input.intellectual_or_learning_disabil, Input.psychiatric_or_mental_illness, Input.other_disability, Input.identity_annotator_count, Input.toxicity_annotator_count, Input.clean, Input.perturbed, Answer.Fair.3, Answer.Likely.4, Answer.Unlikely.2, Answer.Very likely.5, Answer.Very unlikely.1, Answer.answer_time, Answer.clean, Answer.pert_location, Answer.perturbed, Answer.time_spent, Approve, Reject, quality, location, distance, pert_word]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 88 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = df[df[\"Answer.pert_location\"] != df['location']]\n",
    "spam_df\n",
    "# spam_df.groupby(['Answer.clean', 'Answer.perturbed']).filter(lambda x: len(x) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2238, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <th>perturbed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>are you really that stupid</th>\n",
       "      <th>are you really that Stuuupidd</th>\n",
       "      <td>0.903941</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are you that stupid</th>\n",
       "      <th>are you that Stuuupidd</th>\n",
       "      <td>0.930238</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because you are that stupid</th>\n",
       "      <th>because you are that Stuuupidd</th>\n",
       "      <td>0.955592</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bring it fat boy</th>\n",
       "      <th>bring it FATT boy</th>\n",
       "      <td>0.562083</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring it Fatt boy</th>\n",
       "      <td>0.562083</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">you make me sick</th>\n",
       "      <th>you make me Siiiick</th>\n",
       "      <td>0.688390</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you make me sicckkk</th>\n",
       "      <td>0.688390</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you make me sickkkk</th>\n",
       "      <td>0.688390</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">you suck bill walker</th>\n",
       "      <th>you SUUCK bill walker</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you suckkkk bill walker</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            toxicity  \\\n",
       "                                                                mean   \n",
       "clean                       perturbed                                  \n",
       "are you really that stupid  are you really that Stuuupidd   0.903941   \n",
       "are you that stupid         are you that Stuuupidd          0.930238   \n",
       "because you are that stupid because you are that Stuuupidd  0.955592   \n",
       "bring it fat boy            bring it FATT boy               0.562083   \n",
       "                            bring it Fatt boy               0.562083   \n",
       "...                                                              ...   \n",
       "you make me sick            you make me Siiiick             0.688390   \n",
       "                            you make me sicckkk             0.688390   \n",
       "                            you make me sickkkk             0.688390   \n",
       "you suck bill walker        you SUUCK bill walker           0.883333   \n",
       "                            you suckkkk bill walker         0.883333   \n",
       "\n",
       "                                                                                \n",
       "                                                                 min       max  \n",
       "clean                       perturbed                                           \n",
       "are you really that stupid  are you really that Stuuupidd   0.879310  0.928571  \n",
       "are you that stupid         are you that Stuuupidd          0.886792  0.973684  \n",
       "because you are that stupid because you are that Stuuupidd  0.937500  0.973684  \n",
       "bring it fat boy            bring it FATT boy               0.537500  0.586667  \n",
       "                            bring it Fatt boy               0.537500  0.586667  \n",
       "...                                                              ...       ...  \n",
       "you make me sick            you make me Siiiick             0.673077  0.703704  \n",
       "                            you make me sicckkk             0.673077  0.703704  \n",
       "                            you make me sickkkk             0.673077  0.703704  \n",
       "you suck bill walker        you SUUCK bill walker           0.833333  0.933333  \n",
       "                            you suckkkk bill walker         0.833333  0.933333  \n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "test_data = data.groupby(['clean','perturbed']).agg({'toxicity': ['mean', 'min', 'max']})\n",
    "test_data[test_data['toxicity'][\"min\"] != test_data['toxicity']['max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>...</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>clean</th>\n",
       "      <th>perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-22 17:57:45.880275+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>878033.0</td>\n",
       "      <td>163340.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-22 17:57:45.880275+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>878033.0</td>\n",
       "      <td>163340.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-22 17:57:45.880275+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>878033.0</td>\n",
       "      <td>163340.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2017-06-22 01:18:32.437596+00           102.0  5455578.0    347067.0   \n",
       "0  2017-06-22 01:18:32.437596+00           102.0  5455578.0    347067.0   \n",
       "0  2017-06-22 01:18:32.437596+00           102.0  5455578.0    347067.0   \n",
       "0  2017-01-22 17:57:45.880275+00            54.0   878033.0    163340.0   \n",
       "0  2017-01-22 17:57:45.880275+00            54.0   878033.0    163340.0   \n",
       "0  2017-01-22 17:57:45.880275+00            54.0   878033.0    163340.0   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  ...  latino  \\\n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "\n",
       "   other_race_or_ethnicity  physical_disability  \\\n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  identity_annotator_count  toxicity_annotator_count  \\\n",
       "0               NaN                       0.0                      42.0   \n",
       "0               NaN                       0.0                      42.0   \n",
       "0               NaN                       0.0                      42.0   \n",
       "0               NaN                       0.0                      58.0   \n",
       "0               NaN                       0.0                      58.0   \n",
       "0               NaN                       0.0                      58.0   \n",
       "\n",
       "                        clean                      perturbed  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "\n",
       "[6 rows x 45 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are you really that stupid\n",
    "\n",
    "with open('bert_0.5_final_3.pkl', 'rb') as f:\n",
    "    raw_data = pickle.load(f)\n",
    "\n",
    "raw_data[raw_data[\"clean\"] == \"are you really that stupid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>split</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592955</th>\n",
       "      <td>7060854</td>\n",
       "      <td>are you really that stupid?</td>\n",
       "      <td>test</td>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                 comment_text split  \\\n",
       "592955  7060854  are you really that stupid?  test   \n",
       "\n",
       "                         created_date  publication_id  parent_id  article_id  \\\n",
       "592955  2017-06-22 01:18:32.437596+00             102  5455578.0      347067   \n",
       "\n",
       "          rating  funny  wow  ...  white  asian  latino  \\\n",
       "592955  rejected      0    0  ...    NaN    NaN     NaN   \n",
       "\n",
       "        other_race_or_ethnicity  physical_disability  \\\n",
       "592955                      NaN                  NaN   \n",
       "\n",
       "        intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "592955                                  NaN                            NaN   \n",
       "\n",
       "        other_disability  identity_annotator_count  toxicity_annotator_count  \n",
       "592955               NaN                         0                        42  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jigsaw_df = pd.read_csv(\"data/jigsaw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592955</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>are you really that stupid?</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597795</th>\n",
       "      <td>2017-01-22 17:57:45.880275+00</td>\n",
       "      <td>Are you really that stupid!?</td>\n",
       "      <td>0.879310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         created_date                  comment_text  toxicity\n",
       "592955  2017-06-22 01:18:32.437596+00   are you really that stupid?  0.928571\n",
       "597795  2017-01-22 17:57:45.880275+00  Are you really that stupid!?  0.879310"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jigsaw_df[jigsaw_df[\"comment_text\"] == \"are you really that stupid?\"]\n",
    "# jigsaw_df[jigsaw_df[\"created_date\"] == \"2017-01-22 17:57:45.880275+00\"][['created_date','comment_text','toxicity']]\n",
    "jigsaw_df[jigsaw_df['comment_text'].isin(['are you really that stupid?','Are you really that stupid!?'])][['created_date','comment_text','toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>...</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>clean</th>\n",
       "      <th>perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-22 01:18:32.437596+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5455578.0</td>\n",
       "      <td>347067.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>are you really that stupid</td>\n",
       "      <td>are you really that Stuuupidd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2017-06-22 01:18:32.437596+00           102.0  5455578.0    347067.0   \n",
       "0  2017-06-22 01:18:32.437596+00           102.0  5455578.0    347067.0   \n",
       "0  2017-06-22 01:18:32.437596+00           102.0  5455578.0    347067.0   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  ...  latino  \\\n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0  rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "\n",
       "   other_race_or_ethnicity  physical_disability  \\\n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "0                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "0                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  identity_annotator_count  toxicity_annotator_count  \\\n",
       "0               NaN                       0.0                      42.0   \n",
       "0               NaN                       0.0                      42.0   \n",
       "0               NaN                       0.0                      42.0   \n",
       "\n",
       "                        clean                      perturbed  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "0  are you really that stupid  are you really that Stuuupidd  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[raw_data[\"created_date\"] == \"2017-06-22 01:18:32.437596+00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'ABUSIVE', 'score': 0.4526337683200836}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\"\n",
    "API_TOKEN = \"xxxxxx\"\n",
    "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "def query(payload):\n",
    "    data = json.dumps(payload)\n",
    "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "    return json.loads(response.content.decode(\"utf-8\"))\n",
    "data = query(\"indeed what FOL would embrace such a religion\")\n",
    "data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roberta_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_roberta_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_cache = {}\n",
    "for k,v in bert_cache.items():\n",
    "    huggingface_cache[('Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two',k)] = v\n",
    "for k,v in roberta_cache.items():\n",
    "    huggingface_cache[('facebook/roberta-hate-speech-dynabench-r4-target',k)] = v\n",
    "for k,v in twitter_roberta_cache.items():\n",
    "    huggingface_cache[('cardiffnlp/twitter-roberta-base-hate',k)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_predict(row,col_name='Answer.perturbed'):\n",
    "    sentence = row[col_name]\n",
    "    if sentence not in bert_cache:\n",
    "        time.sleep(2)\n",
    "        API_URL = \"https://api-inference.huggingface.co/models/Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\"\n",
    "        API_TOKEN = \"xxxxx\"\n",
    "        headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "        data = json.dumps(sentence)\n",
    "        response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "        res = json.loads(response.content.decode(\"utf-8\"))\n",
    "        print(res)\n",
    "        while 'error' in res or len(res[0]) < 2 or res[0][1]['label'] not in ['ABUSIVE', 'NORMAL']:\n",
    "            print(sentence, res)\n",
    "            time.sleep(30)\n",
    "            response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "            res = json.loads(response.content.decode(\"utf-8\"))\n",
    "        bert_cache[sentence] = res[0][0]['score'] if res[0][0]['label'] == 'ABUSIVE' else res[0][1]['score'] \n",
    "    return bert_cache[sentence]\n",
    "\n",
    "\n",
    "def roberta_predict(row,col_name='Answer.perturbed', roberta_cache=twitter_roberta_cache):\n",
    "    sentence = row[col_name]\n",
    "    if sentence not in roberta_cache:\n",
    "        time.sleep(2)\n",
    "        API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-hate\"\n",
    "        # API_URL = \"https://api-inference.huggingface.co/models/facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "        API_TOKEN = \"xxxxxx\"\n",
    "        headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "        data = json.dumps(sentence)\n",
    "        response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "        res = json.loads(response.content.decode(\"utf-8\"))\n",
    "        print(res)\n",
    "        while 'error' in res or len(res[0]) < 2 or res[0][1]['label'] not in ['hate', 'nothate', 'non-hate']:\n",
    "            print(sentence, res)\n",
    "            time.sleep(30)\n",
    "            response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "            res = json.loads(response.content.decode(\"utf-8\"))\n",
    "        roberta_cache[sentence] = res[0][0]['score'] if res[0][0]['label'] == 'hate' else res[0][1]['score'] \n",
    "    return roberta_cache[sentence]\n",
    "\n",
    "\n",
    "\n",
    "def huggingface_predict(row,col_name, model_name, label_set, positive_label):\n",
    "    sentence = row[col_name]\n",
    "    if (model_name,sentence) not in huggingface_cache:\n",
    "        time.sleep(2)\n",
    "        API_URL = \"https://api-inference.huggingface.co/models/\" + model_name\n",
    "        API_TOKEN = \"xxxxx\"\n",
    "        headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "        data = json.dumps(sentence)\n",
    "        response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "        res = json.loads(response.content.decode(\"utf-8\"))\n",
    "        print(res)\n",
    "        while 'error' in res or len(res[0]) < 2 or res[0][1]['label'] not in label_set:\n",
    "            print(sentence, res)\n",
    "            time.sleep(30)\n",
    "            response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "            res = json.loads(response.content.decode(\"utf-8\"))\n",
    "        huggingface_cache[(model_name,sentence)] = res[0][0]['score'] if res[0][0]['label'] == positive_label else res[0][1]['score'] \n",
    "    return huggingface_cache[(model_name,sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_result_on_clean acc:  0.5673438675696012\n",
      "bert_result_on_perturb acc:  0.5033860045146726\n"
     ]
    }
   ],
   "source": [
    "grouped_multiple['bert_result_on_clean'] = grouped_multiple.apply(bert_predict, args=('Answer.clean',), axis=1)\n",
    "print(\"bert_result_on_clean acc: \", grouped_multiple[grouped_multiple[\"bert_result_on_clean\"] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "# grouped_multiple['perspective_result_on_pert'] = grouped_multiple.apply(perspective_api, args=('Answer.perturbed'), axis=1)\n",
    "grouped_multiple['bert_result_on_perturb'] = grouped_multiple.apply(bert_predict, args=('Answer.perturbed',), axis=1)\n",
    "print(\"bert_result_on_perturb acc: \", grouped_multiple[grouped_multiple[\"bert_result_on_perturb\"] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_result_on_clean acc:  0.7133182844243793\n",
      "roberta_result_on_perturb acc:  0.6132430398796087\n"
     ]
    }
   ],
   "source": [
    "grouped_multiple['roberta_result_on_clean'] = grouped_multiple.apply(roberta_predict, args=('Answer.clean',), axis=1)\n",
    "print(\"roberta_result_on_clean acc: \", grouped_multiple[grouped_multiple[\"roberta_result_on_clean\"] > 0.07].shape[0] / grouped_multiple.shape[0])\n",
    "grouped_multiple['roberta_result_on_perturb'] = grouped_multiple.apply(roberta_predict, args=('Answer.perturbed',), axis=1)\n",
    "print(\"roberta_result_on_perturb acc: \", grouped_multiple[grouped_multiple[\"roberta_result_on_perturb\"] > 0.07].shape[0] / grouped_multiple.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean acc:  0.9149736644093304\n",
      "perturb acc:  0.5229495861550038\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cardiffnlp/roberta-base-offensive'\n",
    "label_set = set(['offensive', 'non-offensive'])\n",
    "pos_label = 'offensive'\n",
    "\n",
    "grouped_multiple[model_name + '_on_clean'] = grouped_multiple.apply(huggingface_predict, args=('Answer.clean',model_name,label_set,pos_label,), axis=1)\n",
    "print(\"clean acc: \", grouped_multiple[grouped_multiple[model_name + '_on_clean'] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "grouped_multiple[model_name + '_on_perturb'] = grouped_multiple.apply(huggingface_predict, args=('Answer.perturbed',model_name,label_set,pos_label,), axis=1)\n",
    "print(\"perturb acc: \", grouped_multiple[grouped_multiple[model_name + '_on_perturb'] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean acc:  0.8969149736644093\n",
      "perturb acc:  0.5575620767494357\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cardiffnlp/bertweet-base-offensive'\n",
    "label_set = set(['LABEL_0', 'LABEL_1'])\n",
    "pos_label = 'LABEL_1'\n",
    "\n",
    "grouped_multiple[model_name + '_on_clean'] = grouped_multiple.apply(huggingface_predict, args=('Answer.clean',model_name,label_set,pos_label,), axis=1)\n",
    "print(\"clean acc: \", grouped_multiple[grouped_multiple[model_name + '_on_clean'] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "grouped_multiple[model_name + '_on_perturb'] = grouped_multiple.apply(huggingface_predict, args=('Answer.perturbed',model_name,label_set,pos_label,), axis=1)\n",
    "print(\"perturb acc: \", grouped_multiple[grouped_multiple[model_name + '_on_perturb'] > 0.5].shape[0] / grouped_multiple.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 1.0\n",
      "0.01 1.0 1.0\n",
      "0.02 1.0 1.0\n",
      "0.03 1.0 1.0\n",
      "0.04 1.0 1.0\n",
      "0.05 0.999 1.0\n",
      "0.06 0.997 1.0\n",
      "0.07 0.995 0.999\n",
      "0.08 0.986 0.999\n",
      "0.09 0.981 0.998\n",
      "0.1 0.968 0.998\n",
      "0.11 0.956 0.998\n",
      "0.12 0.944 0.998\n",
      "0.13 0.93 0.998\n",
      "0.14 0.919 0.998\n",
      "0.15 0.91 0.998\n",
      "0.16 0.898 0.998\n",
      "0.17 0.888 0.998\n",
      "0.18 0.877 0.998\n",
      "0.19 0.862 0.998\n",
      "0.2 0.857 0.995\n",
      "0.21 0.848 0.995\n",
      "0.22 0.845 0.992\n",
      "0.23 0.832 0.989\n",
      "0.24 0.822 0.989\n",
      "0.25 0.808 0.983\n",
      "0.26 0.802 0.983\n",
      "0.27 0.795 0.98\n",
      "0.28 0.783 0.98\n",
      "0.29 0.772 0.979\n",
      "0.3 0.758 0.978\n",
      "0.31 0.748 0.974\n",
      "0.32 0.74 0.973\n",
      "0.33 0.733 0.971\n",
      "0.34 0.722 0.97\n",
      "0.35 0.709 0.965\n",
      "0.36 0.703 0.961\n",
      "0.37 0.69 0.96\n",
      "0.38 0.684 0.957\n",
      "0.39 0.673 0.953\n",
      "0.4 0.667 0.95\n",
      "0.41 0.657 0.946\n",
      "0.42 0.649 0.942\n",
      "0.43 0.643 0.936\n",
      "0.44 0.631 0.933\n",
      "0.45 0.618 0.929\n",
      "0.46 0.605 0.918\n",
      "0.47 0.594 0.913\n",
      "0.48 0.582 0.909\n",
      "0.49 0.57 0.902\n",
      "0.5 0.558 0.897\n",
      "0.51 0.546 0.895\n",
      "0.52 0.536 0.892\n",
      "0.53 0.522 0.883\n",
      "0.54 0.513 0.882\n",
      "0.55 0.501 0.871\n",
      "0.56 0.486 0.865\n",
      "0.57 0.472 0.854\n",
      "0.58 0.46 0.846\n",
      "0.59 0.445 0.838\n",
      "0.6 0.437 0.826\n",
      "0.61 0.43 0.817\n",
      "0.62 0.413 0.809\n",
      "0.63 0.395 0.797\n",
      "0.64 0.375 0.78\n",
      "0.65 0.36 0.762\n",
      "0.66 0.35 0.747\n",
      "0.67 0.333 0.731\n",
      "0.68 0.315 0.719\n",
      "0.69 0.294 0.712\n",
      "0.7 0.281 0.693\n",
      "0.71 0.269 0.674\n",
      "0.72 0.25 0.657\n",
      "0.73 0.233 0.634\n",
      "0.74 0.213 0.609\n",
      "0.75 0.197 0.585\n",
      "0.76 0.184 0.558\n",
      "0.77 0.165 0.524\n",
      "0.78 0.157 0.49\n",
      "0.79 0.138 0.444\n",
      "0.8 0.126 0.399\n",
      "0.81 0.109 0.354\n",
      "0.82 0.09 0.32\n",
      "0.83 0.071 0.278\n",
      "0.84 0.059 0.231\n",
      "0.85 0.047 0.195\n",
      "0.86 0.028 0.151\n",
      "0.87 0.015 0.105\n",
      "0.88 0.008 0.066\n",
      "0.89 0.001 0.029\n",
      "0.9 0.0 0.008\n",
      "0.91 0.0 0.002\n",
      "0.92 0.0 0.0\n",
      "0.93 0.0 0.0\n",
      "0.94 0.0 0.0\n",
      "0.95 0.0 0.0\n",
      "0.96 0.0 0.0\n",
      "0.97 0.0 0.0\n",
      "0.98 0.0 0.0\n",
      "0.99 0.0 0.0\n",
      "1.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "t_generator = (round(x * 0.01,2) for x in range(0, 101))\n",
    "for t in t_generator:\n",
    "    print(t,round(grouped_multiple[grouped_multiple[\"cardiffnlp/bertweet-base-offensive_on_perturb\"] > t].shape[0] / grouped_multiple.shape[0],3),round(grouped_multiple[grouped_multiple[\"cardiffnlp/bertweet-base-offensive_on_clean\"] > t].shape[0] / grouped_multiple.shape[0],3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebd1281c5f5acee8a7f8a313b2ca9c6213b17a23ada965c46f901f6b2a7edb99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
